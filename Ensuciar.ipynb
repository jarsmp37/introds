{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_12692\\2770081182.py:42: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_csv)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def ensuciar_df(df_original):\n",
    "    df = df_original.copy()  # Trabajar sobre una copia del DataFrame original\n",
    "\n",
    "    # Duplicar algunas filas aleatorias\n",
    "    num_duplicados = random.randint(1, int(len(df) * 0.3))  # Hasta 30% de duplicados máximo\n",
    "    duplicadas = df.sample(n=num_duplicados, replace=True)  # Permitir reemplazo\n",
    "    df = pd.concat([df, duplicadas], ignore_index=True)\n",
    "\n",
    "    # Vectorizar la inserción de 'invalid' en el 2% de las celdas sin sobrescribir NaNs\n",
    "    num_invalid = int(len(df) * 0.02)\n",
    "    for col in random.sample(df.columns.tolist(), len(df.columns) // 2):\n",
    "        # Convertir la columna a object si no lo es (para evitar problemas de tipo)\n",
    "        if df[col].dtype != 'object':\n",
    "            df[col] = df[col].astype('object')\n",
    "        valid_indices = df.index[df[col].notna()]  # Obtener índices válidos que no son NaN\n",
    "        if len(valid_indices) > 0:  # Verificar que hay índices válidos\n",
    "            invalid_indices = np.random.choice(valid_indices, size=min(num_invalid, len(valid_indices)), replace=False)  # Elegir solo índices que no son NaN\n",
    "            df.loc[invalid_indices, col] = 'Auto%#'\n",
    "\n",
    "    # Cambiar tipos de formatos de algunas columnas aleatoriamente\n",
    "    columnas_a_cambiar = random.sample(df.columns.tolist(), random.randint(1, len(df.columns) // 2))\n",
    "    for col in columnas_a_cambiar:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].astype(str)  # Convertir a texto\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convertir a numérico donde sea posible\n",
    "\n",
    "    # Vectorizar la inserción de NaNs en el 3% de las celdas\n",
    "    num_nan = int(len(df) * 0.03)\n",
    "    for column in df.columns:\n",
    "        nan_indices = np.random.choice(df.index, size=min(num_nan, len(df)), replace=False)  # Elegir índices aleatorios\n",
    "        df.loc[nan_indices, column] = np.nan  # Insertar NaNs\n",
    "\n",
    "    return df\n",
    "\n",
    "# Cargar un CSV y aplicar las modificaciones\n",
    "ruta_csv = 'poblacion.csv'  # Reemplaza con la ruta de tu archivo CSV\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "max_intentos = 30\n",
    "intento = 0\n",
    "df_sucio = ensuciar_df(df)\n",
    "\n",
    "# Verificar la cantidad de NaNs y volver a ejecutar si es necesario\n",
    "while intento < max_intentos:\n",
    "    # Calcular el porcentaje de NaNs en cada columna\n",
    "    nan_porcentaje = df_sucio.isnull().mean() * 100\n",
    "    # Verificar si alguna columna tiene más del 10% de NaNs\n",
    "    if (nan_porcentaje > 10).any():\n",
    "        intento += 1\n",
    "        #print(f\"Intento {intento}: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\")\n",
    "        df_sucio = ensuciar_df(df)\n",
    "    else:\n",
    "        print(f\"Finalización en el intento {intento}. No se encontraron columnas con más del 10% de NaNs.\")\n",
    "        break\n",
    "\n",
    "# Guardar el DataFrame sucio a un nuevo archivo CSV\n",
    "df_sucio.to_csv('df_sucio.csv', index=False)\n",
    "\n",
    "# Verificar la cantidad de NaNs en el DataFrame final\n",
    "print(df_sucio.isnull().sum())\n",
    "print(df_sucio.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9712, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                     0\n",
       "Gender                                  0\n",
       "Avg_Daily_Screen_Time_hr                0\n",
       "Primary_Device                          0\n",
       "Exceeded_Recommended_Limit              0\n",
       "Educational_to_Recreational_Ratio       0\n",
       "Health_Impacts                       3218\n",
       "Urban_or_Rural                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11533, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sucio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                    567\n",
       "Gender                               11533\n",
       "Avg_Daily_Screen_Time_hr               567\n",
       "Primary_Device                         345\n",
       "Exceeded_Recommended_Limit             345\n",
       "Educational_to_Recreational_Ratio      345\n",
       "Health_Impacts                        4044\n",
       "Urban_or_Rural                         345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sucio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intento 1: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 2: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 3: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 4: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 5: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 6: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 7: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 8: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 9: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 10: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 11: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 12: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 13: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 14: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Intento 15: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\n",
      "Finalización en el intento 15. No se encontraron columnas con más del 10% de NaNs.\n",
      "Employee_ID                           307\n",
      "Age                                   307\n",
      "Gender                                307\n",
      "Job_Role                              307\n",
      "Industry                              307\n",
      "Years_of_Experience                   307\n",
      "Work_Location                         307\n",
      "Hours_Worked_Per_Week                 307\n",
      "Number_of_Virtual_Meetings            307\n",
      "Work_Life_Balance_Rating              307\n",
      "Stress_Level                          307\n",
      "Mental_Health_Condition              1707\n",
      "Access_to_Mental_Health_Resources     307\n",
      "Productivity_Change                   307\n",
      "Social_Isolation_Rating               307\n",
      "Satisfaction_with_Remote_Work         307\n",
      "Company_Support_for_Remote_Work       307\n",
      "Physical_Activity                    6158\n",
      "Sleep_Quality                         307\n",
      "Region                                307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def ensuciar_df(df_original):\n",
    "    df = df_original.copy()  # Trabajar sobre una copia del DataFrame original\n",
    "\n",
    "    # Duplicar algunas filas aleatorias\n",
    "    num_duplicados = random.randint(1, int(len(df) * 0.3))  # Hasta 30% de duplicados máximo\n",
    "    duplicadas = df.sample(n=num_duplicados, replace=True)  # Permitir reemplazo\n",
    "    df = pd.concat([df, duplicadas], ignore_index=True)\n",
    "\n",
    "    # Vectorizar la inserción de 'invalid' en el 2% de las celdas sin sobrescribir NaNs\n",
    "    num_invalid = int(len(df) * 0.02)\n",
    "    for col in random.sample(df.columns.tolist(), len(df.columns) // 2):\n",
    "        # Convertir la columna a object si no lo es (para evitar problemas de tipo)\n",
    "        if df[col].dtype != 'object':\n",
    "            df[col] = df[col].astype('object')\n",
    "        valid_indices = df.index[df[col].notna()]  # Obtener índices válidos que no son NaN\n",
    "        if len(valid_indices) > 0:  # Verificar que hay índices válidos\n",
    "            invalid_indices = np.random.choice(valid_indices, size=min(num_invalid, len(valid_indices)), replace=False)  # Elegir solo índices que no son NaN\n",
    "            df.loc[invalid_indices, col] = 'bbb'\n",
    "\n",
    "    # Cambiar tipos de formatos de algunas columnas aleatoriamente\n",
    "    columnas_a_cambiar = random.sample(df.columns.tolist(), random.randint(1, len(df.columns) // 2))\n",
    "    for col in columnas_a_cambiar:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].astype(str)  # Convertir a texto\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convertir a numérico donde sea posible\n",
    "\n",
    "    # Vectorizar la inserción de NaNs en el 3% de las celdas\n",
    "    num_nan = int(len(df) * 0.05)\n",
    "    for column in df.columns:\n",
    "        nan_indices = np.random.choice(df.index, size=min(num_nan, len(df)), replace=False)  # Elegir índices aleatorios\n",
    "        df.loc[nan_indices, column] = np.nan  # Insertar NaNs\n",
    "\n",
    "    return df\n",
    "\n",
    "# Cargar un CSV y aplicar las modificaciones\n",
    "ruta_csv = 'Impact_of_Remote_Work_on_Mental_Health.csv'  # Reemplaza con la ruta de tu archivo\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "max_intentos = 100\n",
    "intento = 0\n",
    "df_sucio = ensuciar_df(df)\n",
    "\n",
    "# Columnas a excluir del conteo de NaNs\n",
    "columnas_a_excluir = ['Mental_Health_Condition', 'Physical_Activity']\n",
    "\n",
    "# Verificar la cantidad de NaNs y volver a ejecutar si es necesario\n",
    "while intento < max_intentos:\n",
    "    # Calcular el porcentaje de NaNs en cada columna (excluyendo las especificadas)\n",
    "    nan_porcentaje = df_sucio.drop(columns=columnas_a_excluir).isnull().mean() * 100\n",
    "    \n",
    "    # Verificar si alguna columna tiene más del 10% de NaNs\n",
    "    if (nan_porcentaje > 10).any():\n",
    "        intento += 1\n",
    "        print(f\"Intento {intento}: Se encontraron columnas con más del 10% de NaNs. Volviendo a ensuciar el DataFrame.\")\n",
    "        df_sucio = ensuciar_df(df)\n",
    "    else:\n",
    "        print(f\"Finalización en el intento {intento}. No se encontraron columnas con más del 10% de NaNs.\")\n",
    "        break\n",
    "\n",
    "# Guardar el DataFrame sucio a un nuevo archivo CSV\n",
    "df_sucio.to_csv('df_sucio.csv', index=False)\n",
    "\n",
    "# Verificar la cantidad de NaNs en el DataFrame final\n",
    "print(df_sucio.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                                    27\n",
       "Hora de inicio                                                        27\n",
       "Hora de finalización                                                  27\n",
       "Correo electrónico                                                   678\n",
       "Nombre                                                               678\n",
       "Hora de la última modificación                                       678\n",
       "Tomas el STU de CU a CU2 o de CU2 a CU                                27\n",
       "Género                                                               678\n",
       "¿Cuántos días a la semana utilizas el STU?                            96\n",
       "¿Tomas el STU de ida y vuelta?\\n                                      97\n",
       "¿A qué hora tomas el STU de CU a CU2?                                101\n",
       "¿A qué hora tomas el STU de CU2 a CU (Selecciona la más cercana)?     98\n",
       "¿Cuál es tu nivel de satisfacción con el STU?                        678\n",
       " ¿Cuánto tiempo esperas el STU de CU a CU2 (minutos)?                 99\n",
       " ¿Cuánto tiempo esperas el STU de CU2 a CU (minutos)?                102\n",
       "¿Qué tan frecuente es que viajes parado                              100\n",
       "¿Qué consideras qué se debe mejorar en el STU?                       100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sucio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "      <th>cement_co2</th>\n",
       "      <th>cement_co2_per_capita</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>...</th>\n",
       "      <th>share_global_other_co2</th>\n",
       "      <th>share_of_temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_ch4</th>\n",
       "      <th>temperature_change_from_co2</th>\n",
       "      <th>temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_n2o</th>\n",
       "      <th>total_ghg</th>\n",
       "      <th>total_ghg_excluding_lucf</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1750</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2802560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1751</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1752</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1753</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1754</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50186</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>15271377.0</td>\n",
       "      <td>2.514642e+10</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.263</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-8.411</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.348</td>\n",
       "      <td>17.531</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50187</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>15526888.0</td>\n",
       "      <td>2.317871e+10</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.032</td>\n",
       "      <td>8.495</td>\n",
       "      <td>-1.768</td>\n",
       "      <td>-17.231</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.323</td>\n",
       "      <td>15.775</td>\n",
       "      <td>0.612</td>\n",
       "      <td>7.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50188</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>15797220.0</td>\n",
       "      <td>2.514009e+10</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.034</td>\n",
       "      <td>10.204</td>\n",
       "      <td>1.709</td>\n",
       "      <td>20.120</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.549</td>\n",
       "      <td>17.599</td>\n",
       "      <td>0.539</td>\n",
       "      <td>5.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50189</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>16069061.0</td>\n",
       "      <td>2.590159e+10</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.033</td>\n",
       "      <td>10.425</td>\n",
       "      <td>0.221</td>\n",
       "      <td>2.169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.772</td>\n",
       "      <td>17.910</td>\n",
       "      <td>0.315</td>\n",
       "      <td>3.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50190</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>16340829.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.032</td>\n",
       "      <td>11.164</td>\n",
       "      <td>0.739</td>\n",
       "      <td>7.090</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.955</td>\n",
       "      <td>18.608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50191 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  year iso_code  population           gdp  cement_co2  \\\n",
       "0      Afghanistan  1750      AFG   2802560.0           NaN       0.000   \n",
       "1      Afghanistan  1751      AFG         NaN           NaN       0.000   \n",
       "2      Afghanistan  1752      AFG         NaN           NaN       0.000   \n",
       "3      Afghanistan  1753      AFG         NaN           NaN       0.000   \n",
       "4      Afghanistan  1754      AFG         NaN           NaN       0.000   \n",
       "...            ...   ...      ...         ...           ...         ...   \n",
       "50186     Zimbabwe  2019      ZWE  15271377.0  2.514642e+10       0.473   \n",
       "50187     Zimbabwe  2020      ZWE  15526888.0  2.317871e+10       0.496   \n",
       "50188     Zimbabwe  2021      ZWE  15797220.0  2.514009e+10       0.531   \n",
       "50189     Zimbabwe  2022      ZWE  16069061.0  2.590159e+10       0.531   \n",
       "50190     Zimbabwe  2023      ZWE  16340829.0           NaN       0.531   \n",
       "\n",
       "       cement_co2_per_capita     co2  co2_growth_abs  co2_growth_prct  ...  \\\n",
       "0                      0.000     NaN             NaN              NaN  ...   \n",
       "1                        NaN     NaN             NaN              NaN  ...   \n",
       "2                        NaN     NaN             NaN              NaN  ...   \n",
       "3                        NaN     NaN             NaN              NaN  ...   \n",
       "4                        NaN     NaN             NaN              NaN  ...   \n",
       "...                      ...     ...             ...              ...  ...   \n",
       "50186                  0.031  10.263          -0.942           -8.411  ...   \n",
       "50187                  0.032   8.495          -1.768          -17.231  ...   \n",
       "50188                  0.034  10.204           1.709           20.120  ...   \n",
       "50189                  0.033  10.425           0.221            2.169  ...   \n",
       "50190                  0.032  11.164           0.739            7.090  ...   \n",
       "\n",
       "       share_global_other_co2  share_of_temperature_change_from_ghg  \\\n",
       "0                         NaN                                   NaN   \n",
       "1                         NaN                                   NaN   \n",
       "2                         NaN                                   NaN   \n",
       "3                         NaN                                   NaN   \n",
       "4                         NaN                                   NaN   \n",
       "...                       ...                                   ...   \n",
       "50186                     NaN                                 0.106   \n",
       "50187                     NaN                                 0.105   \n",
       "50188                     NaN                                 0.104   \n",
       "50189                     NaN                                 0.103   \n",
       "50190                     NaN                                 0.102   \n",
       "\n",
       "       temperature_change_from_ch4  temperature_change_from_co2  \\\n",
       "0                              NaN                          NaN   \n",
       "1                              NaN                          NaN   \n",
       "2                              NaN                          NaN   \n",
       "3                              NaN                          NaN   \n",
       "4                              NaN                          NaN   \n",
       "...                            ...                          ...   \n",
       "50186                        0.001                        0.001   \n",
       "50187                        0.001                        0.001   \n",
       "50188                        0.001                        0.001   \n",
       "50189                        0.001                        0.001   \n",
       "50190                        0.001                        0.001   \n",
       "\n",
       "       temperature_change_from_ghg  temperature_change_from_n2o  total_ghg  \\\n",
       "0                              NaN                          NaN        NaN   \n",
       "1                              NaN                          NaN        NaN   \n",
       "2                              NaN                          NaN        NaN   \n",
       "3                              NaN                          NaN        NaN   \n",
       "4                              NaN                          NaN        NaN   \n",
       "...                            ...                          ...        ...   \n",
       "50186                        0.002                          0.0     34.348   \n",
       "50187                        0.002                          0.0     31.323   \n",
       "50188                        0.002                          0.0     33.549   \n",
       "50189                        0.002                          0.0     33.772   \n",
       "50190                        0.002                          0.0     33.955   \n",
       "\n",
       "       total_ghg_excluding_lucf  trade_co2  trade_co2_share  \n",
       "0                           NaN        NaN              NaN  \n",
       "1                           NaN        NaN              NaN  \n",
       "2                           NaN        NaN              NaN  \n",
       "3                           NaN        NaN              NaN  \n",
       "4                           NaN        NaN              NaN  \n",
       "...                         ...        ...              ...  \n",
       "50186                    17.531     -0.027           -0.261  \n",
       "50187                    15.775      0.612            7.209  \n",
       "50188                    17.599      0.539            5.280  \n",
       "50189                    17.910      0.315            3.018  \n",
       "50190                    18.608        NaN              NaN  \n",
       "\n",
       "[50191 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(\"owid-co2-data.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                            0\n",
       "year                               0\n",
       "iso_code                        7929\n",
       "population                      9172\n",
       "gdp                            34940\n",
       "                               ...  \n",
       "temperature_change_from_n2o    12131\n",
       "total_ghg                      12781\n",
       "total_ghg_excluding_lucf       12955\n",
       "trade_co2                      45656\n",
       "trade_co2_share                45656\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
